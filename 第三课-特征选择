特征选择:
    属性好坏(信息增益):
        如果一个人50%是男人50%是女人,只能瞎猜,
        如果知道一个属性,此人抽烟还是不抽烟,抽烟的人95%是男生,不抽烟的人20%是男生
        抽烟的人占40%

        熵:
            不确定性 取值(0-1)
        x:{a = "Non-Smoker"; b = "Smoker" }
        在不抽烟的条件下熵为-0.8 * log(2,0.8) - 0.2 * log(2,0.2) = 0.7219
        抽烟的条件下熵为 -0.05 * log(2,0.05) - 0.95 * log(2,0.95) = 0.2864
        则在有抽烟的条件下的熵: ∑(此属性人群的百分比 * 此属性的增益) 0.6 * 不抽烟的熵 + 0.4 * 抽烟的熵 = 0.6 * 0.7219 + 0.4 * 0.2864 = 0.5477
        则抽烟对分辨一个人是男人还是女人的判断增益为 信息增益 = 原本的熵-有此条件的熵 = 1 - 0.5477 = 0.4523 = 抽烟还是不抽烟的价值(0-1)

        信息增益:(男女和抽烟)
                抽烟属性的信息增益=原本的熵 - (抽烟时判断男女的熵 * 抽烟的比例 + 不抽烟的熵 * 不抽烟的比例)
    剪枝处理:
        假设如果一个组的价值要小于另一个组,则这个组的子集也小于另一些组.则在遍历完成另一个组的情况下, 可以不去遍历这个组

        剪纸优化也可以用模拟退火,渐进搜索,遗传算法等去进行优化
    特征选择例子:
        图pic14,对图片进行特征的提取,将大面积的同样色调的地方渲染为黑色
    主成分分析:
        例如照片,从三维压缩到了二维,但仍然可以识别出东西,说明了主成分被保留
        一些呈椭圆高斯分布的点,如果属性在长轴分布的比较开,比较离散,则说明属性的信息量比较大
        如果两个信息有线性关系, 比如近似y = 2x的分布, 则将坐标轴旋转
            Y = PX P为旋转矩阵 见图 pic15以及pic16
        PCA 不能分组,重点在离散程度上,离散越大,越符合PCA降维的标准

        LDA 保留的信息是类的区分信息 投影后信息分辨的比较开 每个类分的越开,越符合LDA的标准 见图pic17, 图中的公式的值越大,越符合LDA降维的标准

        不管是PCA 还是LDA 最终获得的都是投影的方向