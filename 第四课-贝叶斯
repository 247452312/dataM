贝叶斯定理:
    P(A|B) = ( P(B|A) * P(A) ) / P(B)
    概念:B发生的条件下A发生的概率 可以转换为 A发生的条件下B发生的概率乘A发生的概率 除以 B发生的概率

    例子:
        甲射击命中率:0.6
        乙射击命中率:0.5
        已知靶子被命中,求是甲命中的概率

        P(甲命中|靶子命中) = ( P(靶子命中|甲命中) * P(甲命中) ) / P(靶子命中)
            = 1 * 0.6 / (0.6 * 0.5 + 0.4 * 0.5 + 0.6 * 0.5) = 6 / 8
        P(乙命中|靶子命中) = ( P(靶子命中|乙命中) * P(乙命中) ) / P(靶子命中)
            = 1 * 0.5 / (0.6 * 0.5 + 0.4 * 0.5 + 0.6 * 0.5) = 5 / 8

    课后题:
        已知甲乙丙三人射击命中率分别为0.8，0.6和0.5，若每人各开一枪，则目标被命中的概率最接近?
            P(目标被命中) = 1-P(目标没有被命中) = 1 - 0.2 * 0.4 * 0.5 = 0.96

朴素贝叶斯:
    见图pic18,假设条件独立的情况下朴素贝叶斯才能使用

决策树,规则以及树:
    同一个数据集可以生成多个决策树,准确中找最简单的使用,

ID3:
    有的数据不适合加入ID3的算法,比如身份证号等, 因为身份证的信息增益会很大,但是没有必要,也没有合理性.
    公式见图pic19.公式的意义为 如果某个属性将信息拆分的特别碎,则这个属性套用公式splitinformation的值(称为惩罚量)将会高
    过学习:
        在训练集上准确率高, 在检测集上正确率低,
            这个时候要进行剪枝操作,在一部分测试集上进行剪枝的操作,将正确率控制到拐点,也就是最高的时候停止剪枝
    连续性属性在ID3上的应用:
        切开,大于x为一块,小于x为一块

神经网络:
