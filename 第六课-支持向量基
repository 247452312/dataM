SVM:
    从输入空间 向更加高纬度的空间进行映射, 不同的节点分解在高纬度不同区域,形成和其他区域线性可分

    实质:
        形成线性分类器 g(x) = W * X + b
        W的方向和超平面垂直
        那么 X和X在超平面上的投影X`的距离为
            M = ||X - X`||
              = ||入W||
              = (|G(x)| * ||W||) \ w^2
              = |G(x)| / ||W||
    SVM
        实际上,就是将点投影到其他的坐标系,从而将之前的点分开,通过增加维度或者其他的方法分开.


        例如:
            一维平面上红点接近零点,蓝点远离零点,所以, 通过坐标变换,一维坐标为X,二维坐标为X^2,  则,在这个坐标系中就将红点和蓝点分开了,就可以获得一个直线.
    margen:
        通过分界的支持向量点,从而确定分类器的位置可以移动的最大距离.这个值应该越大越好,越大代表了分类器的误差空间大,也就是误差小

    见图pic32,是向高维映射常用的方法

    f(x)是一个 M^2 / 2 维的空间, 即 假设原本是100维的空间,则映射后约是5000维的空间

    两个f(x)维的向量相乘,则计算过程见pic33, 则 f(x) * f(y) = (x*y + 1)^2

    margen转换为目标函数, 可以求目标函数,实际上不能完美的分开, 所以设置soft margin, 将错位的点移到自己的一边去
    以上都属于线性分类器的范畴 ,如果有线性不可分问题的话,原始空间的点映射到高维空间当中,变为线性可分问题. 之前a *b就转换为 f(a)*f(b)
    也有问题,映射也有问题,会使得计算复杂度增加. 所以引出和函数K(a,b) = f(a)*f(b)